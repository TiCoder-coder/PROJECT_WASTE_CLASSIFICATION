PROJECT_DETECT_OBJECT â€” Real-time Object Recognition System (YOLOv11 + SAM2.1 + Classifier)

![Detect Object Preview](https://upload.wikimedia.org/wikipedia/commons/3/38/Detected-with-YOLO--Schreibtisch-mit-Objekten.jpg)

ğŸš€ Overview

    Há»‡ thá»‘ng Realtime Object Detection & Segmentation káº¿t há»£p nhiá»u mÃ´ hÃ¬nh AI máº¡nh máº½:
        - YOLOv11 (Pretrained) â€” DÃ² tÃ¬m váº­t thá»ƒ nhanh vÃ  chÃ­nh xÃ¡c.
        - SAM2.1 (Segment Anything 2) â€” PhÃ¢n vÃ¹ng chÃ­nh xÃ¡c (segmentation) tá»«ng váº­t thá»ƒ Ä‘Æ°á»£c YOLO phÃ¡t hiá»‡n.
        - ResNet18 (Custom Classifier) â€” PhÃ¢n loáº¡i chi tiáº¿t tá»«ng váº­t thá»ƒ dá»±a trÃªn dá»¯ liá»‡u huáº¥n luyá»‡n tÃ¹y chá»‰nh.
        - ImageSearcher (Embedding-based Similarity Search) â€” Khi xÃ¡c suáº¥t tháº¥p, há»‡ thá»‘ng tÃ¬m váº­t thá»ƒ tÆ°Æ¡ng tá»± trong thÆ° viá»‡n annotated/.
        - Object Tracking + Label Stabilization â€” Theo dÃµi váº­t thá»ƒ qua khung hÃ¬nh Ä‘á»ƒ trÃ¡nh nháº¥p nhÃ¡y nhÃ£n.
        - Táº¥t cáº£ Ä‘Æ°á»£c xá»­ lÃ½ real-time tá»« webcam, vá»›i giao diá»‡n hiá»ƒn thá»‹ mask, bounding box, vÃ  tÃªn váº­t thá»ƒ ngay trÃªn mÃ n hÃ¬nh.

ğŸ—ï¸ System Architecture

1ï¸âƒ£ Input Layer â€” Webcam Frame Capture
    - Luá»“ng video láº¥y trá»±c tiáº¿p tá»« webcam (qua cv2.VideoCapture).
    - Má»—i frame Ä‘Æ°á»£c Ä‘Æ°a vÃ o hÃ ng Ä‘á»£i (frame_queue) cho xá»­ lÃ½ ná»n (thread).

2ï¸âƒ£ YOLOv11 Detector
    - Model YOLOv11 pretrained (ultralytics.YOLO) xá»­ lÃ½ detection nhanh chÃ³ng.
    - Xuáº¥t ra danh sÃ¡ch cÃ¡c bounding box [x1, y1, x2, y2].

3ï¸âƒ£ SAM2.1 Segmenter
    - Dá»±a trÃªn YOLO bounding boxes â†’ SAM2.1 táº¡o segmentation mask chÃ­nh xÃ¡c cho tá»«ng váº­t thá»ƒ.
    - Trá»ng sá»‘ tÃ¹y chá»‰nh náº¡p tá»«: data/final_pth_to_webcam/sam2_inference_weights_latest.pth
    - File cáº¥u hÃ¬nh: configs/sam2.1/sam2.1_hiera_b+.yaml
4ï¸âƒ£ Custom Classifier (ResNet18 Fine-tuned)
    - Model ResNet18 Ä‘Æ°á»£c huáº¥n luyá»‡n riÃªng trÃªn dataset 102 lá»›p.
    - Checkpoint: /media/voanhnhat/SDD_OUTSIDE1/PROJECT_DETECT_OBJECT/data/final_pth_to_webcam/sam2_inference_weights_latest.pth
    - Khi phÃ¡t hiá»‡n váº­t thá»ƒ, pháº§n áº£nh Ä‘Æ°á»£c crop theo mask â†’ phÃ¢n loáº¡i qua classifier.

5ï¸âƒ£ Image Searcher (Backup Matching)
    - Náº¿u Ä‘á»™ tin cáº­y cá»§a classifier < 0.85, há»‡ thá»‘ng tÃ¬m áº£nh tÆ°Æ¡ng tá»± nháº¥t trong thÆ° viá»‡n data/annotated/ báº±ng cosine similarity giá»¯a feature embedding.
6ï¸âƒ£ Object Tracker

    - Theo dÃµi cÃ¡c bounding box qua khung hÃ¬nh (IOU-based tracking).

    - LÃ m mÆ°á»£t tá»a Ä‘á»™ vÃ  nhÃ£n váº­t thá»ƒ qua bbox_smooth_alpha.

    - GiÃºp nhÃ£n khÃ´ng nháº¥p nhÃ¡y khi camera di chuyá»ƒn.

7ï¸âƒ£ Display Layer

    - Hiá»ƒn thá»‹ bounding box, mask (mÃ u khÃ¡c nhau) vÃ  label trá»±c tiáº¿p trÃªn video.

    - FPS Ä‘Æ°á»£c tÃ­nh theo thá»i gian thá»±c.

    - CÃ³ thá»ƒ dÃ¹ng cv2.imshow hoáº·c fallback matplotlib náº¿u OpenCV khÃ´ng má»Ÿ Ä‘Æ°á»£c cá»­a sá»•.

ğŸ“‚ Folder Structure

PROJECT_DETECT_OBJECT/
â”œâ”€â”€ ğŸ“ NOTEBOOK_TO_REPORT
â”‚   â”œâ”€â”€ ğŸ“„ Analyst_accuracy_segement.ipynb
â”‚   â”œâ”€â”€ ğŸ“„ Analyst_accuracy_yolo.ipynb
â”‚   â”œâ”€â”€ ğŸ“„ automatic_mask_generator_example.ipynb
â”‚   â”œâ”€â”€ ğŸ“„ image_predictor_example.ipynb
â”‚   â””â”€â”€ ğŸ“„ video_predictor_example.ipynb
â”œâ”€â”€ ğŸ“ configs
â”‚   â”œâ”€â”€ ğŸ“ sam2.1
â”‚   â”‚   â”œâ”€â”€ âš™ï¸ sam2.1_hiera_b+.yaml
â”‚   â”‚   â”œâ”€â”€ âš™ï¸ sam2.1_hiera_l.yaml
â”‚   â”‚   â”œâ”€â”€ âš™ï¸ sam2.1_hiera_s.yaml
â”‚   â”‚   â”œâ”€â”€ âš™ï¸ sam2.1_hiera_t.yaml
â”‚   â”‚   â””â”€â”€ âš™ï¸ sam2.1_hiera_t.yaml.fixed.yaml.fixed.yaml
â”‚   â”œâ”€â”€ ğŸ“ sam2.1_training
â”‚   â”‚   â””â”€â”€ âš™ï¸ sam2.1_hiera_b+_MOSE_finetune.yaml
â”‚   â””â”€â”€ ğŸ“ yolo
â”‚       â””â”€â”€ âš™ï¸ yolo_learning_tools.yaml
â”œâ”€â”€ ğŸ“ sam2

â”‚   â”œâ”€â”€ ğŸ“ sam2
â”‚   â”‚   â”œâ”€â”€ ğŸ“ csrc
â”‚   â”‚   â”‚   â””â”€â”€ ğŸ“„ connected_components.cu
â”‚   â”‚   â”œâ”€â”€ ğŸ“ modeling
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ backbones
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ __init__.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ hieradet.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ image_encoder.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ ğŸ utils.py
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ sam
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ __init__.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ mask_decoder.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ prompt_encoder.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ ğŸ transformer.py
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ memory_attention.py
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ memory_encoder.py
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ position_encoding.py
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ sam2_base.py
â”‚   â”‚   â”‚   â””â”€â”€ ğŸ sam2_utils.py
â”‚   â”‚   â”œâ”€â”€ ğŸ“ utils
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ amg.py
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ misc.py
â”‚   â”‚   â”‚   â””â”€â”€ ğŸ transforms.py
â”‚   â”‚   â”œâ”€â”€ âš™ï¸ _C.so
â”‚   â”‚   â”œâ”€â”€ ğŸ __init__.py
â”‚   â”‚   â”œâ”€â”€ ğŸ automatic_mask_generator.py
â”‚   â”‚   â”œâ”€â”€ ğŸ benchmark.py
â”‚   â”‚   â”œâ”€â”€ ğŸ build_sam.py
â”‚   â”‚   â”œâ”€â”€ âš™ï¸ sam2_hiera_b+.yaml
â”‚   â”‚   â”œâ”€â”€ âš™ï¸ sam2_hiera_l.yaml
â”‚   â”‚   â”œâ”€â”€ âš™ï¸ sam2_hiera_s.yaml
â”‚   â”‚   â”œâ”€â”€ âš™ï¸ sam2_hiera_t.yaml
â”‚   â”‚   â”œâ”€â”€ ğŸ sam2_image_predictor.py
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ sam2_image_predictor.py.bak
â”‚   â”‚   â”œâ”€â”€ ğŸ sam2_train.py
â”‚   â”‚   â”œâ”€â”€ ğŸ sam2_video_predictor.py
â”‚   â”‚   â””â”€â”€ ğŸ sam2_video_predictor_legacy.py
â”‚   â”œâ”€â”€ ğŸ“ tools
â”‚   â”‚   â””â”€â”€ ğŸ vos_inference.py
â”‚   â”œâ”€â”€ ğŸ“ training
â”‚   â”‚   â”œâ”€â”€ ğŸ“ assets
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“„ MOSE_sample_train_list.txt
â”‚   â”‚   â”‚   â””â”€â”€ ğŸ“„ MOSE_sample_val_list.txt
â”‚   â”‚   â”œâ”€â”€ ğŸ“ dataset
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ coco_raw_dataset.py
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ sam2_datasets.py
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ transforms.py
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ utils.py
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ vos_dataset.py
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ vos_raw_dataset.py
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ vos_sampler.py
â”‚   â”‚   â”‚   â””â”€â”€ ğŸ vos_segment_loader.py
â”‚   â”‚   â”œâ”€â”€ ğŸ“ model
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ __init__.py
â”‚   â”‚   â”‚   â””â”€â”€ ğŸ sam2.py
â”‚   â”‚   â”œâ”€â”€ ğŸ“ modeling
â”‚   â”‚   â”‚   â””â”€â”€ ğŸ __init__.py
â”‚   â”‚   â”œâ”€â”€ ğŸ“ scripts
â”‚   â”‚   â”‚   â””â”€â”€ ğŸ sav_frame_extraction_submitit.py
â”‚   â”‚   â”œâ”€â”€ ğŸ“ utils
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ checkpoint_utils.py
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ data_utils.py
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ distributed.py
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ logger.py
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ misc.py
â”‚   â”‚   â”‚   â””â”€â”€ ğŸ train_utils.py
â”‚   â”‚   â”œâ”€â”€ ğŸ“ README.md
â”‚   â”‚   â”œâ”€â”€ ğŸ __init__.py
â”‚   â”‚   â”œâ”€â”€ ğŸ loss_fns.py
â”‚   â”‚   â”œâ”€â”€ ğŸ optimizer.py
â”‚   â”‚   â”œâ”€â”€ ğŸ train.py
â”‚   â”‚   â””â”€â”€ ğŸ trainer.py
â”‚   â”œâ”€â”€ ğŸ __init__.py
â”‚   â”œâ”€â”€ ğŸ“„ backend.Dockerfile
â”‚   â”œâ”€â”€ âš™ï¸ docker-compose.yaml
â”‚   â”œâ”€â”€ âš™ï¸ pyproject.toml
â”‚   â””â”€â”€ ğŸ setup.py
â”œâ”€â”€ ğŸ“ scripts
â”‚   â”œâ”€â”€ ğŸ __init__.py
â”‚   â”œâ”€â”€ ğŸ annote_data.py
â”‚   â”œâ”€â”€ ğŸ create_ann.py
â”‚   â”œâ”€â”€ ğŸ inference_webcam.py
â”‚   â”œâ”€â”€ ğŸ merge_COCO.py
â”‚   â”œâ”€â”€ ğŸ merge_LABEL.py
â”‚   â”œâ”€â”€ ğŸ preprocess_data.py
â”‚   â”œâ”€â”€ ğŸ reaname_file.py
â”‚   â””â”€â”€ ğŸ train.py

âš™ï¸ Environment Setup

1ï¸âƒ£ Create Environment
    cd PROJECT_DETECT_OBJECT
    python3 -m venv .venv
    source .venv/bin/activate

2ï¸âƒ£ Install Dependencies
    pip install -r requirements.txt

3ï¸âƒ£ Checkpoint Preparation
    | Model                     | Path                                                         | Description                    |
    | ------------------------- | ------------------------------------------------------------ | ------------------------------ |
    | **SAM2.1**                | `data/final_pth_to_webcam/sam2_inference_weights_latest.pth` | Custom finetuned SAM weights   |
    | **Classifier (ResNet18)** | `output/experiments/checkpoints/static_finetune_epoch12.pth` | Finetuned classification model |
    | **YOLOv11 Pretrained**    | `checkpoints/yolov11n.pt`                                    | Pretrained detection model     |
    | **Config**                | `configs/sam2.1/sam2.1_hiera_b+.yaml`                        | SAM2 architecture config       |

â–¶ï¸ Run Real-time Detection
    python scripts/inference_webcam.py

ğŸ§© Options

    - Press q to quit webcam window.

    - Modify cam_id if multiple cameras:
        inferencer.run(cam_id=1)
    - Adjust max_draw (number of displayed masks):
        inferencer = WebcamInferencer(..., max_draw=5)

ğŸ’¡ How the Pipeline Works Internally
    1. Capture Frame
        Reads image from webcam in a loop.

    2. Queue Handling
        Frame sent to inference_worker thread.

    3. YOLOv11 Inference
        Detects rough object bounding boxes.

    4. SAM2 Prediction
        Refines detection â†’ pixel-level masks.

    5. Classifier + Image Searcher
        Assigns label using deep classification and similarity matching.

    5. Tracking
        Matches objects across frames using IoU.

    5. Display
        Draw masks, boxes, and names on live webcam feed.

ğŸ§  Performance Notes

    - Uses multi-threading to separate webcam capture and AI inference.

    - Supports both CPU and GPU automatically (cuda or cpu).

    - Can handle ~10â€“15 FPS on RTX 3060 or similar GPU.

ğŸ§¾ Logs & Debugging

| Level           | Prefix                             | Description |
| --------------- | ---------------------------------- | ----------- |
| `[INFO]`        | General system info                |             |
| `[WARN]`        | Missing files / fallback defaults  |             |
| `[SUCCESS]`     | Successful model or label loading  |             |
| `[FATAL ERROR]` | Critical load or inference failure |             |

ğŸ§© Extensions
ğŸ”¹ Replace YOLOv11 model checkpoint with custom trained weights.

ğŸ”¹ Fine-tune SAM2.1 with custom masks dataset.

ğŸ”¹ Add new annotated images for stronger Image Searcher performance.

ğŸ”¹ Integrate SORT/ByteTrack for more stable multi-object tracking.

ğŸ¯ Summary
| Component     | Framework          | Purpose               |
| ------------- | ------------------ | --------------------- |
| YOLOv11       | Ultralytics        | Object Detection      |
| SAM2.1        | Meta FAIR          | Mask Segmentation     |
| ResNet18      | PyTorch            | Object Classification |
| ImageSearcher | Custom             | Similarity Matching   |
| Tracker       | Custom (IOU-based) | Temporal Stability    |

ğŸ–¼ï¸ Output Example
    When webcam runs successfully, you'll see:
        - Colored mask overlay per object
        - Bounding box with label name and confidence
        - Live FPS counter in terminal
